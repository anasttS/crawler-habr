{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Задание 3 - Индекс | Булев поиск.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 3 - Индекс | Булев поиск"
      ],
      "metadata": {
        "id": "V1To4CRh2B8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('wordnet') \n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "FX4teWRq1_c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b61ea98-f1bb-4f3d-d024-a0a19b6e9833"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "ce0h8ii72AjR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uGldByPrQ0tl"
      },
      "outputs": [],
      "source": [
        "# словарь (номер документа -> контент (заголовок + содержимое статьи))\n",
        "content = {}\n",
        "i = 1\n",
        "for file_ in os.listdir('links'):\n",
        "  if (file_.__contains__('.html')):\n",
        "    path_ = os.path.join('links', file_)\n",
        "    file_text = open(path_).read()\n",
        "  \n",
        "    soup = BeautifulSoup(file_text)\n",
        "    \n",
        "    page_content = []\n",
        "    for text in soup.find('h1', {'class': 'tm-article-snippet__title tm-article-snippet__title_h1'}):\n",
        "      title = text.get_text()\n",
        "      page_content.append(title)\n",
        "\n",
        "    data = soup.find('div', {'xmlns': 'http://www.w3.org/1999/xhtml'})\n",
        "    for p in data.find_all('p'):\n",
        "       text = p.get_text()\n",
        "       page_content.append(text)\n",
        "    \n",
        "    content[i] = page_content\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# пример текста 3 документа\n",
        "content[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep5RYibe2cD3",
        "outputId": "44201017-3374-407e-b859-20c47be61805"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Binance и Kraken отказались блокировать россиян: «Это противоречит природе крипты»']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import re"
      ],
      "metadata": {
        "id": "H6f5yEBP4u0B"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(content):\n",
        "    result = []\n",
        "    tokens = set() \n",
        "    for c in content:\n",
        "      tokens_ = nltk.word_tokenize(c)\n",
        "      tokens_ = [i.lower() for i in tokens_]\n",
        "      tokens_ = [i for i in tokens_ if ( i not in string.punctuation )]\n",
        "      tokens_ = filter(None, [re.sub(r\"[^a-zа-я-]+\", r\"\", i) for i in tokens_])\n",
        "\n",
        "      stop_words = stopwords.words('russian')\n",
        "      stop_words.extend(['что', 'это', 'так', 'вот', 'как', 'в', 'к',\n",
        "                         'на', 'о', 'при', 'из-за', 'за', 'ао', 'но', 'х',\n",
        "                         'хотя', 'среди', 'помимо', 'с'])\n",
        "      tokens_ = [i for i in tokens_ if ( i not in stop_words )]\n",
        "\n",
        "      stop_words2 = stopwords.words('english')\n",
        "      stop_words2.extend(['the', 'e', 'a', 'd', 'b', 'x', 'c'])\n",
        "      tokens_ = [i for i in tokens_ if ( i not in stop_words2 )]\n",
        "\n",
        "      tokens_ = [i.replace(\"«\", \"\").replace(\"»\", \"\") for i in tokens_]\n",
        "\n",
        "      for t_ in tokens_:\n",
        "        tokens.add(t_)\n",
        "      result += [tokens]\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "kO9ozM9Y2dmn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index={}\n",
        "for i in range(1, 101):\n",
        "    data = []\n",
        "    for c in tokenize(content[i]):\n",
        "        data += c\n",
        "    data = list(dict.fromkeys(data))\n",
        "    for token in data:\n",
        "        if token in index.keys():\n",
        "            index[token].append(i)\n",
        "        else:\n",
        "            index[token] = [i]"
      ],
      "metadata": {
        "id": "yTu3TPTj61lD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('inverted_index.txt', \"w\", encoding=\"utf-8\") as f:\n",
        "    for key in index:\n",
        "        f.write('{\\\"count\\\":' + str(len(index[key])) + ',\\\"inverted_array\\\":' + str(index[key]) + ',\\\"word\\\":\\\"' + key + '\\\"}\\n')"
      ],
      "metadata": {
        "id": "kRn_i88o5CL6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('inverted_index.txt')"
      ],
      "metadata": {
        "id": "8tg3JfVx8PVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Реализация булева поиска"
      ],
      "metadata": {
        "id": "yt0EEGDp94KT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_for_search(content):\n",
        "    result = []\n",
        "    tokens = set() \n",
        "    \n",
        "    tokens_ = nltk.word_tokenize(content)\n",
        "    tokens_ = [i.lower() for i in tokens_]\n",
        "    tokens_ = [i for i in tokens_ if ( i not in string.punctuation )]\n",
        "    tokens_ = filter(None, [re.sub(r\"[^a-zа-я-]+\", r\"\", i) for i in tokens_])\n",
        "\n",
        "    stop_words = stopwords.words('russian')\n",
        "    stop_words.extend(['что', 'это', 'так', 'вот', 'как', 'в', 'к',\n",
        "                         'на', 'о', 'при', 'из-за', 'за', 'ао', 'но', 'х',\n",
        "                         'хотя', 'среди', 'помимо', 'с'])\n",
        "    tokens_ = [i for i in tokens_ if ( i not in stop_words )]\n",
        "\n",
        "    stop_words2 = stopwords.words('english')\n",
        "    stop_words2.extend(['the', 'e', 'a', 'd', 'b', 'x', 'c'])\n",
        "    tokens_ = [i for i in tokens_ if ( i not in stop_words2 )]\n",
        "\n",
        "    tokens_ = [i.replace(\"«\", \"\").replace(\"»\", \"\") for i in tokens_]\n",
        "\n",
        "    for t_ in tokens_:\n",
        "      tokens.add(t_)\n",
        "    result += [tokens]\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "DV-Waovr_qI0"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "request = \"крипты AND блокировать OR ai\"\n",
        "tokens_search = []\n",
        "for t in preprocess_for_search(request):\n",
        "    tokens_search += t"
      ],
      "metadata": {
        "id": "sUvjHKwGAipL"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_asv08q_OlS",
        "outputId": "25bb200d-1cda-43c3-ef9d-51b118edd8e2"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['блокировать', 'крипты', 'ai']"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# поиск пересечения нужных слов и слов из созданного индекса\n",
        "def find_token_in_index(token):\n",
        "  search = {}\n",
        "  if token in index.keys():\n",
        "        search[token] = index[token]\n",
        "  else:\n",
        "        search[token] = []\n",
        "  return search"
      ],
      "metadata": {
        "id": "5D060eMW-zoT"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "request = request.split(' OR ')"
      ],
      "metadata": {
        "id": "A_8xpxHVBAhS"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = {}\n",
        "docs = []\n",
        "for req in request:\n",
        "  ands = req.split(' AND ')\n",
        "  temp_searched_docs = []\n",
        "  temp_result = []\n",
        "  for token in ands:\n",
        "    d = find_token_in_index(token)\n",
        "    if d[token]: \n",
        "      temp_searched_docs.append(d[token])\n",
        "    else: \n",
        "      temp_searched_docs = []\n",
        "      break\n",
        "  if temp_searched_docs:\n",
        "    temp_result = list(set.intersection(*map(set, temp_searched_docs)))\n",
        "    if temp_result:\n",
        "      result[req] = temp_result\n",
        "      docs.append(temp_result)\n"
      ],
      "metadata": {
        "id": "AVyXOQbjAYDw"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajjep-2DBFLD",
        "outputId": "624ea860-b85b-4d59-f480-0f3f2ccca59f"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ai': [10], 'крипты AND блокировать': [3]}"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Документы - результат запроса\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNQjAKVSKgzx",
        "outputId": "d10d3095-11da-4220-8220-31ca9a9acf93"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3], [10]]"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Прошлый вариант булева поиска\n"
      ],
      "metadata": {
        "id": "cwYlqmUEJbfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Текст - Тело упадет со скоростью 2,6 тыс. м/c (из 3 документа)\n",
        "text = \"Тело упадет со скоростью 2,6 тыс. м/c\"\n",
        "tokens_search_ = []\n",
        "for t in preprocess_for_search(text):\n",
        "    tokens_search_ += t"
      ],
      "metadata": {
        "id": "Pokpmy8BJefN"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_search_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9ik-x-YJyeu",
        "outputId": "d70e2351-bf1b-4efc-bba2-d5e17b1f9aa3"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['мc', 'скоростью', 'тыс', 'упадет', 'тело']"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# поиск пересечения нужных слов и слов из созданного индекса\n",
        "search = {}\n",
        "for token in tokens_search_:\n",
        "    if token in index.keys():\n",
        "        search[token] = index[token]\n",
        "    else:\n",
        "        search[token] = []"
      ],
      "metadata": {
        "id": "6IBl5E6pJz-q"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXFmCxOVJ_qH",
        "outputId": "17b8210f-ac04-4602-8b42-81483de47a05"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'мc': [8, 91],\n",
              " 'скоростью': [8, 79, 91],\n",
              " 'тело': [2, 91],\n",
              " 'тыс': [5, 7, 17, 68, 91, 99],\n",
              " 'упадет': [91]}"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bool_search(search_type, search):\n",
        "  i = 1\n",
        "  document = []\n",
        "  for token in search:\n",
        "      if i == 1:\n",
        "        document = search[token]\n",
        "      else:\n",
        "        if search_type == 'AND':\n",
        "           # все токены должны быть в документе\n",
        "          document = list(set(document) & set(search[token]))\n",
        "        if search_type == 'OR':\n",
        "           # достаточно хотя бы одного токена в документе\n",
        "          document = list(set(document) | set(search[token]))\n",
        "      i += 1\n",
        "  print(document)"
      ],
      "metadata": {
        "id": "Z7ydRBPdKBAJ"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bool_search('AND', search)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBp7d9PnKC6M",
        "outputId": "1bf128c6-a875-44f6-e87a-ae34c5ba708f"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[91]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bool_search('OR', search)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQSC8DiVKFiZ",
        "outputId": "6285d339-f560-4b98-c13e-e9c7b4fc9e5d"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 99, 68, 5, 7, 8, 79, 17, 91]\n"
          ]
        }
      ]
    }
  ]
}