{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Задание 2 - Токенизация | Лемматизация.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 2 - Токенизация | Лемматизация"
      ],
      "metadata": {
        "id": "-wUzXNKbAoGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "R3e0yNUACriG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "id": "8NoNhkFKcEbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('wordnet') \n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "AwoNJmmFC5tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "Nirp5zVwEyeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "1O1VmAuExGfq"
      },
      "outputs": [],
      "source": [
        "# Контент включается в себя заголовок и основной текст новостной статьи\n",
        "content = []\n",
        "\n",
        "for file_ in os.listdir('links'):\n",
        "  if (file_.__contains__('.html')):\n",
        "    path_ = os.path.join('links', file_)\n",
        "    file_text = open(path_).read()\n",
        "  \n",
        "    soup = BeautifulSoup(file_text)\n",
        "  \n",
        "    for text in soup.find('h1', {'class': 'tm-article-snippet__title tm-article-snippet__title_h1'}):\n",
        "      title = text.get_text()\n",
        "      content.append(title)\n",
        "\n",
        "    data = soup.find('div', {'xmlns': 'http://www.w3.org/1999/xhtml'})\n",
        "    for p in data.find_all('p'):\n",
        "       text = p.get_text()\n",
        "       content.append(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        " \n",
        "# В тексте большое количество английских слов, связанных с IT и соответственно\n",
        "# существенно значимых для поиска, поэтому токены содержат русские и английские слова\n",
        "def tokenize(content):\n",
        "    tokens = set() \n",
        "    for c in content:\n",
        "      tokens_ = nltk.word_tokenize(c)\n",
        "      tokens_ = [i.lower() for i in tokens_]\n",
        "      tokens_ = [i for i in tokens_ if ( i not in string.punctuation )]\n",
        "      tokens_ = filter(None, [re.sub(r\"[^a-zа-я-]+\", r\"\", i) for i in tokens_])\n",
        "\n",
        "      stop_words = stopwords.words('russian')\n",
        "      stop_words.extend(['что', 'это', 'так', 'вот', 'как', 'в', 'к',\n",
        "                         'на', 'о', 'при', 'из-за', 'за', 'ао', 'но', 'х',\n",
        "                         'хотя', 'среди', 'помимо', 'с'])\n",
        "      tokens_ = [i for i in tokens_ if ( i not in stop_words )]\n",
        "\n",
        "      stop_words2 = stopwords.words('english')\n",
        "      stop_words2.extend(['the', 'e', 'a', 'd', 'b', 'x', 'c'])\n",
        "      tokens_ = [i for i in tokens_ if ( i not in stop_words2 )]\n",
        "\n",
        "      tokens_ = [i.replace(\"«\", \"\").replace(\"»\", \"\") for i in tokens_]\n",
        "\n",
        "      for t_ in tokens_:\n",
        "        tokens.add(t_)\n",
        " \n",
        "    return tokens"
      ],
      "metadata": {
        "id": "FDOt06Haxwz0"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy2\n",
        "\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "def lemmatize(tokens):\n",
        "  lemmas = {}\n",
        "  for token in tokens:\n",
        "    lemma = morph.parse(token)[0].normal_form\n",
        "    flag = lemmas.get(lemma)\n",
        "    if flag is None:\n",
        "      lemmas[lemma] = token\n",
        "    else:\n",
        "      if token not in flag:\n",
        "        lemmas[lemma] = flag + ' ' + token\n",
        "  return lemmas"
      ],
      "metadata": {
        "id": "On2GeAt0MeLQ"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenize(content)"
      ],
      "metadata": {
        "id": "ZtnmafiyRd1B"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas = lemmatize(tokens)"
      ],
      "metadata": {
        "id": "OuGyWIonari0"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_1 = open('tokens.txt', \"w\")\n",
        "for token in tokens:\n",
        "  file_1.write(token + '\\n')\n",
        "file_1.close()\n",
        "\n",
        "file_2 = open('lemmas.txt', \"w\")\n",
        "for key in lemmas:\n",
        "  res = key + ':'\n",
        "  for i in lemmas[key]:\n",
        "    res = res  + i\n",
        "  file_2.write(res + '\\n')\n",
        "file_2.close()"
      ],
      "metadata": {
        "id": "GC2SzU5ScprJ"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"lemmas.txt\")\n",
        "files.download(\"tokens.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "iUbRwa_wiZOV",
        "outputId": "65ff53cc-cd58-456b-ad33-335ea86a33e3"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_04ce1e80-05e3-43ec-8be7-f65751967a49\", \"lemmas.txt\", 186192)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d0f6f8fb-d992-463a-8e84-2d789f2ea5ec\", \"tokens.txt\", 120602)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}