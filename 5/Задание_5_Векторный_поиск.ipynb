{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Задание 5 - Векторный поиск.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Векторный поиск"
      ],
      "metadata": {
        "id": "lEtZuw5AMFpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pymorphy2\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from scipy import spatial\n",
        "import json\n",
        "import string"
      ],
      "metadata": {
        "id": "--rOKc_NdHE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "MspKu_Bqfc1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# откроем инвертированный список лемм (создан в 4 задании)\n",
        "with open('inverted_index_lemmas.txt', encoding=\"utf-8\") as file:\n",
        "    rows = [row.strip() for row in file]\n",
        "\n",
        "index_lemmas = {}\n",
        "lemmas = list()\n",
        "for row in rows:\n",
        "    row = row.replace('\\'', '\\\"')\n",
        "    dict_ = json.loads(row)\n",
        "    lemmas.append(dict_[\"word\"])\n",
        "    index_lemmas[dict_[\"word\"]] = [dict_[\"count\"], dict_[\"inverted_array\"]]"
      ],
      "metadata": {
        "id": "lbnbfUvFffAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# обработка контента (токенизация, удаление стоп-слов, знаков препинания)\n",
        "def tokenize(content):\n",
        "    tokens_ = nltk.word_tokenize(content)\n",
        "    tokens_ = [i.lower() for i in tokens_]\n",
        "    tokens_ = [i for i in tokens_ if ( i not in string.punctuation )]\n",
        "    tokens_ = filter(None, [re.sub(r\"[^a-zа-я-]+\", r\"\", i) for i in tokens_])\n",
        "\n",
        "    stop_words = stopwords.words('russian')\n",
        "    stop_words.extend(['что', 'это', 'так', 'вот', 'как', 'в', 'к',\n",
        "                         'на', 'о', 'при', 'из-за', 'за', 'ао', 'но', 'х',\n",
        "                         'хотя', 'среди', 'помимо', 'с'])\n",
        "    tokens_ = [i for i in tokens_ if ( i not in stop_words )]\n",
        "\n",
        "    stop_words2 = stopwords.words('english')\n",
        "    stop_words2.extend(['the', 'e', 'a', 'd', 'b', 'x', 'c'])\n",
        "    tokens_ = [i for i in tokens_ if ( i not in stop_words2 )]\n",
        "\n",
        "    tokens_ = [i.replace(\"«\", \"\").replace(\"»\", \"\") for i in tokens_]\n",
        "\n",
        "    return tokens_"
      ],
      "metadata": {
        "id": "k_oMtwZylYzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создание матрицы по индексу лемм\n",
        "# строки - документы, столбцы - леммы, пересечения - существует ли данная лемма в данном документе\n",
        "def get_matrix_lemmas(index_lemmas):\n",
        "  id = 0\n",
        "  matrix = []\n",
        "  for i in range(len(index_lemmas)):\n",
        "    matrix.append([0] * 100)\n",
        "  for k in index_lemmas:\n",
        "    docs = index_lemmas[k][1]\n",
        "    for doc in docs:\n",
        "        matrix[id][int(doc) - 1] = 1\n",
        "    id += 1\n",
        "  return np.array(matrix).transpose()"
      ],
      "metadata": {
        "id": "zyC7zTeIf0Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_matrix_lemmas(index_lemmas).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9WNdONtKUu2",
        "outputId": "0c11b3e1-b5c3-49f5-b788-0864b3147595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 4365)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# создание вектора размером кол-ва лемм, значения которого 0 или 1 в зависимости от лемм поисковой фразы\n",
        "def get_vector_from_search_query(search):\n",
        "    morph = pymorphy2.MorphAnalyzer()\n",
        "    tokens = tokenize(search)\n",
        "    lemmas_from_tokens = [morph.parse(token)[0].normal_form for token in tokens]\n",
        "    vector = [0] * len(lemmas)\n",
        "    for token in lemmas_from_tokens:\n",
        "        if token in lemmas:\n",
        "            vector[lemmas.index(token)] = 1\n",
        "    return vector"
      ],
      "metadata": {
        "id": "co7ZzQrIlPir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = get_matrix_lemmas(index_lemmas)"
      ],
      "metadata": {
        "id": "UBwpXRSXElC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция поиска: строки матрицы сравниваем с вектором через косинусное расстояние, \n",
        "# и записываем для каждого документа значение - степень сходства\n",
        "# чем ближе значение косинуса к 1, тем ближе угол к 0 градусам, то есть тем более похожи два вектора\n",
        "def search(search):\n",
        "    vector = get_vector_from_search_query(search)\n",
        "    docs = dict()\n",
        "    for id, doc in enumerate(matrix):\n",
        "        docs[id + 1] = spatial.distance.cosine(vector, doc)\n",
        "    sorted_ = sorted(docs.items(), key=lambda x: x[1])\n",
        "    sorted_docs = []\n",
        "    for item in sorted_:\n",
        "        sorted_docs.append(item[0])\n",
        "    return sorted_docs"
      ],
      "metadata": {
        "id": "c2vGZjFElvOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_top5(search_):\n",
        "  docs = search(search_)\n",
        "  print(docs[:5])"
      ],
      "metadata": {
        "id": "6TzfFQxKOqDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_docs = search('Тело упадет со скоростью')\n",
        "result_docs[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce9rxwsUPMbv",
        "outputId": "05802650-4715-4312-c298-b4c765c3db40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[87, 38, 7, 62, 16, 98, 95, 69, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13]"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_top5('Тело упадет со скоростью')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ResR552pgG_5",
        "outputId": "b8ddb52e-05ab-49d6-b8ad-643e661e3479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[87, 38, 7, 62, 16]\n"
          ]
        }
      ]
    }
  ]
}